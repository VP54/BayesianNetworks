{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ce5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MATH AND DATA PROCESSING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from math import lgamma, log\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "## PLOT\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "## OS and sys\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from itertools import product, chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735f0cef-93fd-481f-8895-00185508b61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore, PC, ParameterEstimator\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator as MLE\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.global_vars import SHOW_PROGRESS\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pgmpy.base import DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e54a4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ML_score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2f24505",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('./data/x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8ec70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataParameter:\n",
    "    def __init__(self, NODE_SIZE, NUM_BINS, NUM_BINS_SMALL):\n",
    "        self.NODE_SIZE = NODE_SIZE\n",
    "        self.NUM_BINS = NUM_BINS\n",
    "        self.NUM_BINS_SMALL = NUM_BINS_SMALL\n",
    "        \n",
    "    def plot(self, model):\n",
    "        plt.figure(figsize=(8, 6), dpi=100)  \n",
    "        \n",
    "        nx.draw(model, with_labels=True, node_size = self.node_sizes)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        axis = plt.gca()\n",
    "        axis.set_xlim([1.2*x for x in axis.get_xlim()])\n",
    "        axis.set_ylim([1.2*y for y in axis.get_ylim()])\n",
    "        \n",
    "        return plt.show()\n",
    "\n",
    "    def get_disc_data(self, disc_data):\n",
    "\n",
    "        teplota = self.cutting_cond(disc_data['Teplota vzduchu'])\n",
    "        rychlost = self.cutting_cond(disc_data['Rychlost otáček'])\n",
    "        krout = self.cutting_cond(disc_data['Kroutící moment'])\n",
    "        opo = self.cutting_cond(disc_data['Opotřebení nástroje'])\n",
    "        \n",
    "        return disc_data, teplota, rychlost, krout, opo\n",
    "    \n",
    "    def cutting_cond(self, x):\n",
    "        return (min(x), max(x), (max(x) - min(x)) / self.NUM_BINS)\n",
    "    \n",
    "    def cutting_cond_small(self, x):\n",
    "        return (min(x), max(x) + 20, ((max(x) + 20) - (min(x))) / self.NUM_BINS_SMALL)\n",
    "    \n",
    "    def bin_data(self, x_test, data_to_be_replaced = None):\n",
    "        NUM_BINS = self.NUM_BINS\n",
    "        NUM_BINS_SMALL = self.NUM_BINS_SMALL\n",
    "        \n",
    "        \n",
    "        disc_data = x_test.copy()\n",
    "        disc_data, teplota, rychlost, krout, opo = self.get_disc_data(disc_data)\n",
    "        \n",
    "        teplota = self.cutting_cond(disc_data['Teplota vzduchu'])\n",
    "        rychlost = self.cutting_cond(disc_data['Rychlost otáček'])\n",
    "        krout = self.cutting_cond(disc_data['Kroutící moment'])\n",
    "        opo = self.cutting_cond_small(disc_data['Opotřebení nástroje'])\n",
    "        \n",
    "        disc_data['T'] = pd.cut(x = disc_data['Teplota vzduchu'], bins = np.arange(teplota[0], teplota[1], teplota[2]), labels = np.arange(0, NUM_BINS - 1, 1))\n",
    "        disc_data['R'] = pd.cut(x = disc_data['Rychlost otáček'], bins = np.arange(rychlost[0], rychlost[1], rychlost[2]), labels = np.arange(0, NUM_BINS - 1, 1))\n",
    "        disc_data['K'] = pd.cut(x = disc_data['Kroutící moment'], bins = np.arange(krout[0], krout[1], krout[2]), labels = np.arange(0, NUM_BINS - 1, 1))\n",
    "        disc_data['O'] = pd.cut(x = disc_data['Opotřebení nástroje'], bins = np.arange(opo[0], opo[1], opo[2]), labels = np.arange(0, NUM_BINS_SMALL - 1, 1))\n",
    "\n",
    "        y_test = disc_data['Porucha']\n",
    "        disc_data = disc_data.dropna(how = 'any')\n",
    "        \n",
    "        return disc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f538662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class ClassificationMetrics:\n",
    "    \n",
    "    def __init__(self, real, predicted, target_variable):\n",
    "        self.real = real\n",
    "        self.predicted = predicted\n",
    "        self.target_variable = target_variable\n",
    "        \n",
    "    def _classify_points(self):\n",
    "        \n",
    "        true_ones = 0\n",
    "        true_zeros = 0\n",
    "        false_ones = 0\n",
    "        false_zeros = 0\n",
    "        good = 0\n",
    "        err = 0\n",
    "        \n",
    "        for i, ii in list(zip(self.real, self.predicted)):\n",
    "            if ii != i:\n",
    "                err += 1\n",
    "                if ii == 1:\n",
    "                    false_ones += 1\n",
    "                else:\n",
    "                    false_zeros += 1\n",
    "            else:\n",
    "                good += 1\n",
    "                if i == 1:\n",
    "                    true_ones += 1\n",
    "                else:\n",
    "                    true_zeros += 1\n",
    "                    \n",
    "        self.err = err\n",
    "        self.good = good\n",
    "        self.false_ones = false_ones\n",
    "        self.false_zeros = false_zeros\n",
    "        self.true_ones = true_ones\n",
    "        self.true_zeros = true_zeros\n",
    "        \n",
    "    def _get_overall_prob(self):\n",
    "        self._classify_points()\n",
    "        \n",
    "        return self.good / (self.good + self.err)\n",
    "    \n",
    "    def _return_false_good_vals(self):\n",
    "        self._classify_points()\n",
    "        \n",
    "        return self.good, self.err, self.false_ones, self.false_zeros, self.true_ones, self.true_zeros\n",
    "    \n",
    "    def _plot_conf_matrix(self):\n",
    "        import seaborn as sns\n",
    "        data = np.matrix([[self.true_zeros, self.false_ones], [self.false_zeros, self.true_ones]])\n",
    "        sns.heatmap(data, annot=True,  linewidths=.5,cmap='Blues', fmt='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a117437-f25d-424e-8578-d8700a5c7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(cpd):\n",
    "    backup = TabularCPD._truncate_strtable\n",
    "    TabularCPD._truncate_strtable = lambda self, x: x\n",
    "    print(cpd)\n",
    "    TabularCPD._truncate_strtable = backup\n",
    "    \n",
    "\n",
    "preprocess_pearson = PreprocessDataParameter(\n",
    "    NODE_SIZE = 5000,\n",
    "    NUM_BINS = 12,\n",
    "    NUM_BINS_SMALL = 12\n",
    ")\n",
    "\n",
    "preprocess_hc = PreprocessDataParameter(\n",
    "    NODE_SIZE = 5000,\n",
    "    NUM_BINS = 6,\n",
    "    NUM_BINS_SMALL = 6\n",
    ")\n",
    "\n",
    "\n",
    "pearson_data = preprocess_pearson.bin_data(x_test = x_test)\n",
    "hc_data = preprocess_hc.bin_data(x_test = x_test)\n",
    "\n",
    "pearson_test = preprocess_pearson.bin_data(x_test = pd.read_csv(\"./data/x_test_miss.csv\"))\n",
    "hc_test = preprocess_hc.bin_data(x_test = pd.read_csv(\"./data/x_test_miss.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1bc6d68",
   "metadata": {},
   "source": [
    "## Structure Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b134d-1fe5-474a-8b53-f930427d07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gs = HillClimbSearch(hc_data[['Teplota vzduchu', 'Rychlost otáček', 'Kroutící moment', 'Opotřebení nástroje', 'Porucha']])\n",
    "ml_model = gs.estimate(scoring_method = MLScore(hc_data[['Teplota vzduchu', 'Rychlost otáček', 'Kroutící moment', 'Opotřebení nástroje', 'Porucha']]), max_iter = 150, show_progress = True)\n",
    "\n",
    "\n",
    "ml_model.edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de14b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = [(\"Porucha\", \"O\"), (\"Porucha\", \"R\"), (\"Porucha\", \"T\"), (\"Porucha\", \"K\")]\n",
    "fixed_edges = [('R', 'K')]\n",
    "\n",
    "\n",
    "\n",
    "gs = HillClimbSearch(hc_data[['Teplota vzduchu', 'Rychlost otáček', 'Kroutící moment', 'Opotřebení nástroje', 'Porucha']])\n",
    "ml_model = gs.estimate(scoring_method = MLScore(hc_data[['Teplota vzduchu', 'Rychlost otáček', 'Kroutící moment', 'Opotřebení nástroje', 'Porucha']]), max_iter = 150, show_progress = True, black_list=black_list, fixed_edges=fixed_edges)\n",
    "\n",
    "\n",
    "ml_model.edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd682034-13bb-4f43-933a-3c13eb9aff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PC(data=pearson_data[['Teplota vzduchu', 'Rychlost otáček', 'Kroutící moment', 'Opotřebení nástroje', 'Porucha']])\n",
    "pc_model_peaerson = pc.estimate(ci_test = 'pearsonr', significance_level=0.05)\n",
    "\n",
    "pc_model_peaerson.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4471b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNetwork([('O', 'Porucha')])\n",
    "estimator = MLE(BayesianNetwork(model), hc_data[['K', 'T', 'R', 'O', 'Porucha']])\n",
    "\n",
    "\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('O'))\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('Porucha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34d25b-c98c-4ba3-9362-0e74ab636c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BayesianNetwork([('K', 'Porucha'), ('O', 'Porucha'), ('R', 'K')])\n",
    "\n",
    "estimator = MLE(BayesianNetwork(model), hc_data[['K', 'T', 'R', 'O', 'Porucha']])\n",
    "\n",
    "\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('R'))\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('K'))\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('O'))\n",
    "print(MLE(model, hc_data[['K', 'T', 'R', 'O', 'Porucha']]).estimate_cpd('Porucha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6b6305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02d65fa831f46b09ed27dcdc6bef68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9738327347357619"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BayesianNetwork([(\"O\", \"Porucha\")])\n",
    "\n",
    "m.fit(pearson_data[['O', 'Porucha']])\n",
    "lst = m.predict(pearson_test[['O']])\n",
    "\n",
    "metrics = ClassificationMetrics(\n",
    "    real = pearson_test['Porucha'].values,\n",
    "    predicted = lst['Porucha'].values,\n",
    "    target_variable=\"Porucha\"\n",
    ")\n",
    "\n",
    "metrics._get_overall_prob()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5d63259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553b43ce9c64d9499b22b7dbbd40aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9803481190342505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BayesianNetwork([('K', 'Porucha'), ('O', 'Porucha'), ('R', 'K')])\n",
    "\n",
    "m.fit(hc_data[['O', 'Porucha', 'K', 'R']])\n",
    "lst = m.predict(hc_test[['O', 'K', 'R']])\n",
    "\n",
    "metrics = ClassificationMetrics(\n",
    "    real = hc_test['Porucha'].values,\n",
    "    predicted = lst['Porucha'].values,\n",
    "    target_variable=\"Porucha\"\n",
    ")\n",
    "\n",
    "metrics._get_overall_prob()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
