{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpectationMaximization(ParameterEstimator):\n",
    "    def __init__(self, model, data, **kwargs):\n",
    "\n",
    "        if not isinstance(model, BayesianNetwork):\n",
    "            raise NotImplementedError(\n",
    "                \"Expectation Maximization is only implemented for BayesianNetwork\"\n",
    "            )\n",
    "\n",
    "        super(ExpectationMaximization, self).__init__(model, data, **kwargs)\n",
    "        self.model_copy = self.model.copy()\n",
    "\n",
    "    def _get_likelihood(self, datapoint):\n",
    "\n",
    "        likelihood = 1\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            for cpd in self.model_copy.cpds:\n",
    "                scope = set(cpd.scope())\n",
    "                likelihood *= cpd.get_value(\n",
    "                    **{key: value for key, value in datapoint.items() if key in scope}\n",
    "                )\n",
    "        return likelihood\n",
    "\n",
    "    def _compute_weights(self, latent_card):\n",
    "\n",
    "        cache = []\n",
    "\n",
    "        data_unique = self.data.drop_duplicates()\n",
    "        n_counts = self.data.groupby(list(self.data.columns)).size().to_dict()\n",
    "\n",
    "        for i in range(data_unique.shape[0]):\n",
    "            v = list(product(*[range(card) for card in latent_card.values()]))\n",
    "            latent_combinations = np.array(v, dtype=int)\n",
    "            df = data_unique.iloc[[i] * latent_combinations.shape[0]].reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "            for index, latent_var in enumerate(latent_card.keys()):\n",
    "                df[latent_var] = latent_combinations[:, index]\n",
    "\n",
    "            weights = df.apply(lambda t: self._get_likelihood(dict(t)), axis=1)\n",
    "            df[\"_weight\"] = (weights / weights.sum()) * n_counts[\n",
    "                tuple(data_unique.iloc[i])\n",
    "            ]\n",
    "            cache.append(df)\n",
    "\n",
    "        return pd.concat(cache, copy=False), weights.sum()\n",
    "\n",
    "    def _is_converged(self, new_cpds, atol=1e-08):\n",
    "        \"\"\"\n",
    "        Checks if the values of `new_cpds` is within tolerance limits of current\n",
    "        model cpds.\n",
    "        \"\"\"\n",
    "        for cpd in new_cpds:\n",
    "            print(type(cpd))\n",
    "            if not cpd.__eq__(self.model_copy.get_cpds(node=cpd.scope()[0]), atol=atol):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_parameters(\n",
    "        self,\n",
    "        latent_card=None,\n",
    "        max_iter=100,\n",
    "        atol=1e-08,\n",
    "        n_jobs=-1,\n",
    "        seed=None,\n",
    "        show_progress=True,\n",
    "    ):\n",
    "\n",
    "        # Step 1: Parameter checks\n",
    "        if latent_card is None:\n",
    "            latent_card = {var: 2 for var in self.model_copy.latents}\n",
    "\n",
    "        # Step 2: Create structures/variables to be used later.\n",
    "        n_states_dict = {key: len(value) for key, value in self.state_names.items()}\n",
    "        n_states_dict.update(latent_card)\n",
    "        for var in self.model_copy.latents:\n",
    "            self.state_names[var] = list(range(n_states_dict[var]))\n",
    "\n",
    "        # Step 3: Initialize random CPDs if starting values aren't provided.\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        cpds = []\n",
    "        for node in self.model_copy.nodes():\n",
    "            parents = list(self.model_copy.predecessors(node))\n",
    "            cpds.append(\n",
    "                TabularCPD.get_random(\n",
    "                    variable=node,\n",
    "                    evidence=parents,\n",
    "                    cardinality={\n",
    "                        var: n_states_dict[var] for var in chain([node], parents)\n",
    "                    },\n",
    "                    state_names={\n",
    "                        var: self.state_names[var] for var in chain([node], parents)\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.model_copy.add_cpds(*cpds)\n",
    "\n",
    "        if show_progress and SHOW_PROGRESS:\n",
    "            pbar = tqdm(total=max_iter)\n",
    "\n",
    "        # Step 4: Run the EM algorithm.\n",
    "        iter_counter = 0\n",
    "        for i in range(max_iter):\n",
    "            print(iter_counter)\n",
    "            \n",
    "            # Step 4.1: E-step: Expands the dataset and computes the likelihood of each\n",
    "            #           possible state of latent variables.\n",
    "            weighted_data, log_lik = self._compute_weights(latent_card)\n",
    "            # Step 4.2: M-step: Uses the weights of the dataset to do a weighted MLE.\n",
    "            new_cpds = MaximumLikelihoodEstimator(\n",
    "                self.model_copy, weighted_data\n",
    "            ).get_parameters(n_jobs=n_jobs, weighted=True)\n",
    "            \n",
    "            iter_counter += 1\n",
    "            print(iter_counter)\n",
    "\n",
    "            # Step 4.3: Check of convergence and max_iter\n",
    "            if self._is_converged(new_cpds, atol=atol):\n",
    "                if show_progress and SHOW_PROGRESS:\n",
    "                    pbar.close()\n",
    "                return {\"cpds\": new_cpds,\n",
    "                        \"iter\": 'converged',\n",
    "                        \"LL\": log_lik\n",
    "                \n",
    "                }\n",
    "\n",
    "            else:\n",
    "\n",
    "                self.model_copy.cpds = new_cpds\n",
    "                if show_progress and SHOW_PROGRESS:\n",
    "                    pbar.update(1)\n",
    "        \n",
    "\n",
    "        return {    \"cpds\": cpds,\n",
    "                    \"iter\": \"non-converged\",\n",
    "                    \"LL\": log_lik\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
